{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a7442-1ef8-47ea-a5c8-cc9fae96213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values.\n",
    "--------\n",
    "Missing data is a common and inherent issue in data collection, especially when working with large datasets. \n",
    "There are various reasons for missing data, such as incomplete information provided by participants, \n",
    "non-response from those who decline to share information, poorly designed surveys, or removal of data for confidentiality reasons.\n",
    "\n",
    "There are three main types of missing data:\n",
    "1. Missing Completely at Random (MCAR)\n",
    "2. Missing at Random (MAR)\n",
    "3. Missing Not at Random (MNAR).\n",
    "\n",
    "Missing data shpuld be handled properly because, if teh data is missing then it may end up building a biased machine learning model, leading to incorrect results.\n",
    "\n",
    "Algorithms that are not affected by missing data:\n",
    "    Histogram based Gradient-boosting Classifier / Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27abc67-dd40-4ded-a1e9-de29b4439df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "-----------\n",
    "\n",
    "1. Drop \n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "## deleting missing row\n",
    "df.dropna()\n",
    "## deleting column wise\n",
    "df.dropna(axis=1)\n",
    "\n",
    "2. Mean Value Imputation\n",
    "df['Age_Mean'] = df['age'].fillna(df['age'].mean())\n",
    "\n",
    "3. Median value Imputation\n",
    "df['Age_Median'] = df['age'].fillna(df['age'].median())\n",
    "\n",
    "4. Mode Imputation (For categorical Values)\n",
    "mode_value = df[df['embarked'].notna()]['embarked'].mode()[0]\n",
    "df['embarked_mode'] = df['embarked'].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfb257-4011-4dd7-b52d-ebfccf3e6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "-----------\n",
    "Imbalanced data is a common problem in machine learning, which brings challenges to feature correlation, class separation and evaluation, and results in poor model performance.\n",
    "\n",
    "If Imbalanced data set is not handled then it will lead algorithms to get good results by returning the majority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6fa09-eae0-4251-a2ee-03e11461ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required.\n",
    "--------\n",
    "Upsampling refers to the technique to create artificial or duplicate data points or of the minority class sample to balance the class label.\n",
    "    Upsampling is required to transform the dataset such that it contains equal number of classes in target value.\n",
    "    Example: When the amount of data collected is in-sufficient, then we will use up-sampling.\n",
    "    \n",
    "Downsampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "    Down-sampling is required to transform the dataset such that it contains equal number of classes in target value.\n",
    "    Example: If we need smaller model that doesnot require large space , we use downsampling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538f68e-432c-46f4-aa24-44b48dfc6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "-------\n",
    "Data augmentation is a set of techniques to artificially increase the amount of data by generating new data points from existing data.\n",
    "\n",
    "SMOTE is a technique in machine learning for dealing with issues that arise when working with an unbalanced data set.\n",
    "SMOTE is a data augmentation algorithm that creates synthetic data points from raw data. \n",
    "SMOTE can be thought of as a more sophisticated version of oversampling or a specific data augmentation algorithm. \n",
    "SMOTE has the advantage of not creating duplicate data points, but rather synthetic data points that differ slightly from the original data points.\n",
    "SMOTE is a superior oversampling option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc156f-c73a-4c1c-8707-6c44cd178e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "---------\n",
    "An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.\n",
    "\n",
    "It is essential to handle outliers because:\n",
    "    Outliers in input data can skew and mislead the training process of machine learning algorithms resulting in longer training times, less accurate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9003fea-d4ad-4c09-b7a6-873457bad320",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "--------\n",
    "Techniques that can be used to analyse customer data having missing data set:\n",
    "1. Drop missing values (either drop row or drop columns)\n",
    "2. Mean Value Imputation (replace the missing value with mean value)\n",
    "3. Median value Imputation (replace the missing value with median value)\n",
    "4. Mode Imputation (For categorical Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589460c-8b86-4508-9434-576f95dc7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?\n",
    "-------\n",
    "If there is no significant difference between our primary variable of interest and the missing and \n",
    "non-missing values we have evidence that our data is missing at random.\n",
    "\n",
    "To check if your data are Missing At Random, take each column with missingness and recode it as one if it is missing and zero otherwise.\n",
    "Then regress each of the the other variables onto it using a logistic regression. \n",
    "A significant p-value indicates an association between the regressor and missingness, meaning your data are Missing At Random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e207f98-c8db-4378-a419-03b3c859d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "-------\n",
    "For this dataset we can use:\n",
    "Random Over-Sampling :   \n",
    "The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfishing.\n",
    "Oversampling can be defined as adding more copies to the minority class. Oversampling can be a good choice when you donâ€™t have a ton of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491eabad-bf97-4b95-a8c6-a6ec6d58b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?\n",
    "-------\n",
    "For this dataset we can use:\n",
    "Random Under-Sampling :   \n",
    "In under-sampling, the simplest technique involves removing random records from the majority class, which can cause a loss of information. \n",
    "Undersampling can be defined as removing some observations of the majority class. This is done until the majority and minority class is balanced out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6837862-50d1-47c4-b093-e3ad9eade026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?\n",
    "------\n",
    "For this dataset we can use:\n",
    "SMOTE : \n",
    "SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. \n",
    "The synthetic points are added between the chosen point and its neighbors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
