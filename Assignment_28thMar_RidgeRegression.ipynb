{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ecd7ba-e640-4df7-bbad-69b6b247888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n",
    "----------\n",
    "Ridge regression is a method of estimating the coefficients of multiple-regression models in scenarios where the independent variables are highly correlated.\n",
    "\n",
    "Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator.\n",
    "The ordinary least squares model seeks to find the coefficients that minimize the mean squared error. \n",
    "On the other hand, Ridge Regression tries to find the coefficients that minimize the mean squared error and wants the magnitude of coefficients to be as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828cfeba-1bf5-4289-b3d0-d1ab376c57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the assumptions of Ridge Regression?\n",
    "----------\n",
    "Assumptions of Regression Analysis\n",
    "The chosen sample is representative of the population.\n",
    "There is a linear relationship between the independent variable(s) and the dependent variable.\n",
    "All the variables are normally distributed; to check, plot a histogram of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fed316-e89f-4179-9071-943640c4177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n",
    "----------\n",
    "Lambda is chosen using cross validation.\n",
    "The idea is to make the fit small by making the residual sum or squares small plus adding a shrinkage penalty. \n",
    "The shrinkage penalty is lambda times the sum of squares of the coefficients so coefficients that get too large are penalized. \n",
    "As lambda gets larger, the bias is unchanged but the variance drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfaac02-4bc6-4f48-8366-dc27d5791764",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Can Ridge Regression be used for feature selection? If yes, how?\n",
    "----------\n",
    "Ridge Regression uses an L1 penalty to control the strength of the regularization, which can also lead to feature selection but may not set any coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f146b-316c-4cbe-b9d0-e4b675f49075",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. How does the Ridge Regression model perform in the presence of multicollinearity?\n",
    "----------\n",
    "Multicollinearity happens when predictor variables exhibit a correlation among themselves. \n",
    "Ridge regression aims at reducing the standard error by adding some bias in the estimates of the regression. \n",
    "The reduction of the standard error in regression estimates significantly increases the reliability of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f1cf7-1a6b-4227-90af-2be3a006efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Can Ridge Regression handle both categorical and continuous independent variables?\n",
    "----------\n",
    "Yes, Ridge Regression can handle categorical variables.\n",
    "Through the model, we are able to see object types of variables or categorical variables are more significant than continuous variables.\n",
    "In this model, will scale the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b16bbc-0e37-486f-87b8-88ce9b3c2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. How do you interpret the coefficients of Ridge Regression?\n",
    "----------\n",
    "The ridge coefficients are a reduced factor of the simple linear regression coefficients and thus never attain zero values but very small values. \n",
    "The regression coefficient is the slope of the regression line.\n",
    "We find the regression coefficient by dividing the covariance of your independent and dependent variables by the variance of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dba60c-cdec-47f5-a7cd-1788609e8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?\n",
    "----------\n",
    "Yes, The ridge regression technique can be used to predict time-series. \n",
    "Ridge regression (RR) can also solve the multicollinearity problem that exists in linear regression.\n",
    "We will estimate the coefficients of the model, which represent the strength and direction of the relationship between the dependent and independent variables.\n",
    "Before estimating the model, we need to split the data into training and testing sets. \n",
    "Weâ€™ll use the first 80% of the data for training the model and the remaining 20% of the data for testing the model.\n",
    "X = data['Price'].shift(1)\n",
    "y = data['Price']\n",
    "\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_X, test_X = X[1:train_size], X[train_size:]\n",
    "train_y, test_y = y[1:train_size], y[train_size:]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
