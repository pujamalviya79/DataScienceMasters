{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5d89e-3839-483e-b40f-381f7b847921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "----------\n",
    "Lasso Regression is a regularization technique used in feature selection using a Shrinkage method also referred to as the penalized regression method. \n",
    "Lasso is short for Least Absolute Shrinkage and Selection Operator, which is used both for regularization and model selection.\n",
    "\n",
    "Ridge Regression adds a penalty term proportional to the square of the coefficients, \n",
    "while Lasso adds a penalty term proportional to the absolute value of the coefficients, which can lead to variable selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ae6d1-2c3a-41c0-8071-05d0cdb7677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "----------\n",
    "Main advantages of Lasso Regression are:\n",
    "    1. Feature selection: Lasso helps identify the most important features, making the model more interpretable.\n",
    "    2. Reduces overfitting: By adding a penalty term, Lasso reduces the risk of overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1831c8-9a09-43f6-9388-e481235ba786",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "---------\n",
    "The lasso performs shrinkage so that there are \"corners'' in the constraint, which in two dimensions corresponds to a diamond. \n",
    "If the sum of squares \"hits'' one of these corners, then the coefficient corresponding to the axis is shrunk to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d544d-e6a5-46f6-befa-d6966bbeb259",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "----------\n",
    "A tuning parameter (Œª), sometimes called a penalty parameter, controls the strength of the penalty term in lasso regression. \n",
    "It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean.\n",
    "\n",
    "The model with tuning parameter Œª is fit to the training subset, and goodness-of-fit (MSE) is calculated for the test subset. \n",
    "The Œª value that produces the greatest goodness-of-fit is picked as the tuning parameter to be used in the LASSO regression on the whole data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba89853-ffa8-4a0d-8a49-9e9fb1129969",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "-----------\n",
    "Yes, Lasso Regression can be used for non-linear regression problems, if we can linearize the model.\n",
    "\n",
    "The essential part of LASSO is just adding an L1 norm of the coefficients to the main term,\n",
    "ùëì(ùë•,ùë¶,ùõΩ)+ùúÜ‚ÄñùõΩ‚Äñ1.\n",
    "\n",
    "There's no reason ùëì has to be a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fccb9-cf70-49ee-a4f8-33468a675422",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "-----------\n",
    "Ridge Regression:\n",
    "    Ridge Regression adds a penalty term proportional to the square of the coefficients.\n",
    "    Shrinks the coefficients toward zero.\n",
    "    Does not eliminate any features.\n",
    "    Suitable when all features are important.\n",
    "    More computationally efficient.\n",
    "    Requires setting a hyperparameter.\n",
    "    Performs better when there are many small to medium-sized coefficients.\n",
    "Lasso Regression:\n",
    "    Lasso adds a penalty term proportional to the absolute value of the coefficients, which can lead to variable selection.\n",
    "    Shrinks the coefficients toward zero and Encourages some coefficients to be exactly zero.\n",
    "    Can eliminate some features.\n",
    "    Suitable when some features are irrelevant or redundant.\n",
    "    Less computationally efficient.\n",
    "    Requires setting a hyperparameter.\n",
    "    Performs better when there are a few large coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a87bf6-c1fe-4796-91be-3f04924823b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "-----------\n",
    "Yes, Lasso Regression can handle multicollinearity in the input features.\n",
    "Because of LASSO's built-in variable selection, it can handle some multicollinearity without sacrificing interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d6c18-1b60-4886-a5ca-00f3ce82cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "-----------\n",
    "To select Lambda value in LASSO regression, it is recommended to use the Œª that is within one standard error of the minimum \n",
    "because it will often lead to a more parsimonious model with fewer included variables and a minimal loss in mean squared error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
