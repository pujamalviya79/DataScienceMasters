{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1c115f-f851-4dbf-988a-044939c0401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "-----\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. \n",
    "Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "\n",
    "Web scraping is used in a variety of digital businesses that rely on data harvesting. \n",
    "\n",
    "Three areas where Web Scrapping is used: \n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. \n",
    "Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. \n",
    "High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company.\n",
    "This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9a5f1-44cd-4b1f-b3c9-018f00d44f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "------\n",
    "\n",
    "Different methods for Web Scrapping are:\n",
    "1. MANUAL SCRAPING\n",
    "    COPY-PASTING - In manual scraping, we copy and paste web content.\n",
    "\n",
    "2. AUTOMATED SCRAPING\n",
    "    HTML PARSING - HTML parsing is done with JavaScript and targets linear or nested HTML pages.\n",
    "    DOM PARSING - DOM is short for Document Object Model and it defines the style structure and content of XML files.\n",
    "    VERTICAL AGGREGATION - Vertical aggregation platforms are created by companies with access to large scale computing power to target specific verticals.\n",
    "    XPATH - XML Path Language is a query language that is used with XML documents.\n",
    "    GOOGLE SHEETS - Google sheets are a web scraping tool that is quite popular among web scrapers.\n",
    "    TEXT PATTERN MATCHING - This is a matching technique that involves the use of the UNIX grep command and is used with popular programming languages like Perl or Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062727d-469e-4000-aae7-0fb934fab214",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "----\n",
    "\n",
    "Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. \n",
    "It is a tool for web scraping that helps to clean up and parse the documents that have been pulled down from the web.\n",
    "\n",
    "Beautiful Soup creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ba8cc-d3ff-4322-b933-abaac479caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "------\n",
    "Flask is a lightweight framework to build websites. \n",
    "We'll use this to parse our collected data and display it as HTML in a new HTML file.\n",
    "The requests module allows us to send http requests to the website we want to scrape. \n",
    "The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f90e1-8234-40ba-9941-61e854d02b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "------\n",
    "AWS services used:\n",
    "1. Amazon Elastic Beanstalk - Amazon Elastic Beanstalk is a web infrastructure management service.\n",
    "    It handles deployment and scaling for web applications and services.\n",
    "2. AWS CodePipeline - AWS CodePipeline is a fully managed continuous delivery service that helps you automate release pipelines \n",
    "    for fast and reliable application and infrastructure updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
