{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5d78ff8-f69c-4a11-8523-74cd68368171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [0.27272727 0.625     ]\n",
      " [0.         1.        ]\n",
      " [1.         0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "--------\n",
    "Min-Max Scaling is a way of data scaling, where the minimum of feature is made equal to zero and the maximum of feature equal to one.\n",
    "MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range.\n",
    "It scales the values to a specific value range without changing the shape of the original distribution.\n",
    "\n",
    "Example:\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "# create data\n",
    "data = [[11, 2], [3, 7], [0, 10], [11, 8]]\n",
    " \n",
    "# scale features\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(data)\n",
    "scaled_data=model.transform(data)\n",
    " \n",
    "# print scaled features\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510fa1a4-4259-4bad-bdc2-cd49385632bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        WEIGHT  PRICE\n",
      "Orange      15      1\n",
      "Apple       18      3\n",
      "Banana      12      2\n",
      "Grape       10      5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Orange</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Banana</th>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grape</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          WEIGHT     PRICE\n",
       "Orange  0.272727  0.090909\n",
       "Apple   0.327273  0.272727\n",
       "Banana  0.218182  0.181818\n",
       "Grape   0.181818  0.454545"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "------\n",
    "A vector is a quantity that has both magnitude, as well as direction.\n",
    "A vector that has a magnitude of 1 is a unit vector.\n",
    "Unit Vector is a technique where the unit vector has the same direction as a given vector, we divide the vector by its magnitude.\n",
    "For example, consider a vector v = (1, 4) which has a magnitude of |v|. \n",
    "If we divide each component of vector v by |v| we will get the unit vector uv which is in the same direction as v.\n",
    "\n",
    "whereas , Min-Max Scaling is a way of data scaling, where the minimum of feature is made equal to zero and the maximum of feature equal to one.\n",
    "\n",
    "Example:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({'WEIGHT': [15, 18, 12,10],\n",
    "                   'PRICE': [1,3,2,5]},\n",
    "                   index = ['Orange','Apple','Banana','Grape'])\n",
    "print(df)\n",
    "\n",
    "df1 = df.apply(lambda x : x/np.linalg.norm(x,1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30812141-0211-4c8e-92db-6661c3d904ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "--------\n",
    "PCA is a tool for identifying the main axes of variance within a data set and allows for easy data exploration to understand the key variables in the data and spot outliers.\n",
    "Principal Component Analysis (PCA) is an unsupervised linear transformation technique that is widely used across different fields, most prominently for feature extraction and dimensionality reduction. \n",
    "\n",
    "PCA can be used by following below approach:\n",
    "- Standardize the d-dimensional dataset.\n",
    "- Construct the covariance matrix.\n",
    "- Decompose the covariance matrix into its eigenvectors and eigenvalues.\n",
    "- Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.\n",
    "- Select k eigenvectors which correspond to the k largest eigenvalues, where k is the dimensionality of the new feature subspace (k ≤ d).\n",
    "- Construct a projection matrix W from the “top” k eigenvectors.\n",
    "- Transform the d-dimensional input dataset X using the projection matrix W to obtain the new k-dimensional feature subspace.\n",
    "\n",
    "Example:\n",
    "    Principal Component Analysis can be used in Image compression. Image can be resized as per the requirement and patterns can be determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f7e4b-c3ed-44a3-b54d-e23dc2467c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "--------\n",
    "PCA is an important method for feature extraction and image representation. \n",
    "In PCA, matrix transformation of the image takes place into high dimension vectors and its covariance matrix is obtained consuming high-dimension vector space.\n",
    "PCA reduces the dimensionality without losing information from any features.\n",
    "\n",
    "Examples:\n",
    "Some real-world applications of PCA are image processing, movie recommendation system, optimizing the power allocation in various communication channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe523f9-ec4a-46c7-9baf-6b76a77e2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  Rating  Delivery Time\n",
      "0    100       3              3\n",
      "1    200       5              7\n",
      "2    250       4              6\n",
      "------------\n",
      "[[0.         0.         0.        ]\n",
      " [0.66666667 1.         1.        ]\n",
      " [1.         0.5        0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "'''Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "------'''\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[100, 3,3], [200, 5,7], [250, 4,6]]\n",
    "df = pd.DataFrame(data, columns=['Price', 'Rating','Delivery Time'])\n",
    "print(df)\n",
    "print('------------')\n",
    "scaler = MinMaxScaler()\n",
    "model=scaler.fit(data)\n",
    "scaled_data=model.transform(data)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1053022-f48f-44a2-b9f2-268fe3702a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "-------\n",
    "Steps for PCA:\n",
    "- Standardize the d-dimensional dataset.\n",
    "- Construct the covariance matrix.\n",
    "- Decompose the covariance matrix into its eigenvectors and eigenvalues.\n",
    "- Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.\n",
    "- Select k eigenvectors which correspond to the k largest eigenvalues, where k is the dimensionality of the new feature subspace (k ≤ d).\n",
    "- Construct a projection matrix W from the “top” k eigenvectors.\n",
    "- Transform the d-dimensional input dataset X using the projection matrix W to obtain the new k-dimensional feature subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b2525-fb3d-48d9-9df9-7d054451ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "-------\n",
    "x=[1,5,10,15,20]\n",
    "To normalize in [−1,1]\n",
    "x′′=2 ((x−minx)/(maxx−minx))−1\n",
    "x1=[-1,-0.579,-0.052,0.475,1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e67f18a-b40c-4603-a60c-38080453593f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height  Weight  Age  Gender  BloodPressure\n",
      "0     150      53   32    Male            120\n",
      "1     160      55   71  Female            110\n",
      "2     152      54   61    Male             90\n",
      "[[-2.00000000e+00  2.77555756e-16  1.11022302e-16  1.11022302e-16]\n",
      " [ 2.00000000e+00 -2.77555756e-16 -1.11022302e-16 -1.11022302e-16]]\n"
     ]
    }
   ],
   "source": [
    "'''Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "-------'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = [[150,53,32,'Male',120], [160,55,71,'Female',110], [152,54,61,'Male',90]]\n",
    "df = pd.DataFrame(data, columns=['Height', 'Weight','Age','Gender','BloodPressure'])\n",
    "print(df)\n",
    "\n",
    "categorical_columns = df.columns[df.dtypes == object]\n",
    "df = pd.get_dummies(df, columns = categorical_columns, drop_first=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(df[df.columns[df.columns != 'BloodPressure']],\n",
    "                   df['BloodPressure'], test_size=0.25, random_state=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "from numpy.linalg import eigh\n",
    "cov_matrix = np.cov(X_train_std, rowvar=False)\n",
    "egnvalues, egnvectors = eigh(cov_matrix)\n",
    "total_egnvalues = sum(egnvalues)\n",
    "var_exp = [(i/total_egnvalues) for i in sorted(egnvalues, reverse=True)]\n",
    "\n",
    "egnpairs = [(np.abs(egnvalues[i]), egnvectors[:, i])\n",
    "                for i in range(len(egnvalues))]\n",
    "egnpairs.sort(key=lambda k: k[0], reverse=True)\n",
    "projectionMatrix = np.hstack((egnpairs[0][1][:, np.newaxis],\n",
    "                              egnpairs[1][1][:, np.newaxis],\n",
    "                              egnpairs[2][1][:, np.newaxis],\n",
    "                              egnpairs[3][1][:, np.newaxis]))\n",
    "\n",
    "X_train_pca = X_train_std.dot(projectionMatrix)\n",
    "print(X_train_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
